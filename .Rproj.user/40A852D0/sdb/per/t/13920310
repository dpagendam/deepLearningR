{
    "collab_server" : "",
    "contents" : "---\ntitle: \"The Cells Dataset\"\nauthor: <span style=\"color:#16a085\">Christopher K. Wikle & Dan Pagendam</span>\noutput: ioslides_presentation\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n\n## The Cells Dataset\n- The data for this exercise was obtained from http://www.robots.ox.ac.uk/~vgg/research/counting/index_org.html\n- It consists of 200 synthetic <span style=\"color:#16a085\">fluorescence microscopy images</span> of bacterial cells.\n- Each image has a number of cells in it and the file name contains the number of cells.\n- This is quite a small dataset and will hopefully show you that huge volumes of data is not always necessary for using Deep Neural Networks.\n- We will also look at how we can get more out of a small dataset using <span style=\"color:#16a085\">*data augmentation*</span>.\n- We will build a CNN model that can predict the number of cells in an image\n\n\n## Required Packages\n- For this exerice you will require the following packages:\n    - <span style=\"color:#16a085\">pbapply</span>\n    - <span style=\"color:#16a085\">EBImage</span>\n- You can install and load these as follows:\n```{r echo = TRUE}\n#install.packages(\"pbapply\")\nlibrary(pbapply)\n\nlibrary(\"devtools\")\n#install_github(\"aoles/EBImage\")\nlibrary(EBImage)\nlibrary(keras)\nlibrary(deepLearningR)\n```\n\n\n\n## Load the Cells Data\n- The true cell counts corresponding to the images have been stored in an RData file.\n```{r echo = TRUE}\ndata(cells)\n```\n\n- The images are colour and 256x256 pixels so we will <span style=\"color:#16a085\">reduce the image resolution</span>.\n- reducing the image resolution will speed up model fitting.\n- it will also reduce the number of <span style=\"color:#16a085\">*features*</span> coming out of our final convolutional layer (therefore fewer parameters).\n```{r echo = TRUE}\ngrayScale <- FALSE\nwidth <- 64\nheight <- 64\n```\n\n\n## Load the Cells Data\n- Load in the data from the directories of images.\n- Check that the image pixels have been scaled appropriately.\n```{r echo = TRUE}\npackageDataDir = system.file(\"extdata\", package=\"deepLearningR\")\ntrainData <- extract_feature(paste0(packageDataDir, \"/cells/train/\"),                               width, height, grayScale, TRUE)\ntrainData$y <- cellCounts[21:200]\nprint(range(trainData$X))\n```\n\n\n## Load the Cells Data\n- Load in the data from the directories of images.\n- Check that the image pixels have been scaled appropriately.\n```{r echo = TRUE}\ntestData <- extract_feature(paste0(packageDataDir, \"/cells/test/\"),                                width, height, grayScale, TRUE)\ntestData$y <- cellCounts[1:20]\nprint(range(testData$X))\n```\n\n\n\n\n##  Data Formatting for a CNN in Keras\n- Remember, all of our data needs to be in a tensor where the first dimension corresponds to the observations/samples.\n```{r echo = TRUE}\nnumInputChannels <- 3\ntrain_array <- t(trainData$X)\ndim(train_array) <- c(width, height, numInputChannels, \n                      nrow(trainData$X))\ntrain_array <- aperm(train_array, c(4,1,2,3))\n  \ntest_array <- t(testData$X)\ndim(test_array) <- c(width, height, numInputChannels, \n                     nrow(testData$X))\ntest_array <- aperm(test_array, c(4,1,2,3))\n```\n\n##  Data Augmentation\n- Keras includes an <span style=\"color:#16a085\">image_data_generator</span> function that can be used in conjunction with <span style=\"color:#16a085\">flow_images_from_data</span>.\n```{r echo = TRUE}\ndatagen <- image_data_generator(\n  rescale = 1/255,\n  rotation_range = 0,\n  shear_range = 0,\n  zoom_range = 0,\n  horizontal_flip = TRUE,\n  vertical_flip = TRUE,\n  fill_mode = \"wrap\",\n  width_shift_range = 0.05,\n  height_shift_range = 0.05\n)\n```\n\n\n##  Data Augmentation\n```{r echo = TRUE}\nnumNewImages <- 300\nbatchSize = 50\nd <- dim(train_array)\ntrain_array_augmented <- array(NA, c(d[1] + numNewImages, d[2:4]))\ntrain_array_augmented[1:d[1], , , ] <- train_array\ny_augmented <- trainData$y\nfor(i in 1:(numNewImages/batchSize))\n{\n    augmentation_generator <- flow_images_from_data(x = train_array,\n                              y = trainData$y,generator = datagen,\n                              batch_size = batchSize)\n    newImages <- generator_next(augmentation_generator)\n    fromInd = d[1] + (i-1)*batchSize + 1\n    toInd = d[1] + i*batchSize\n    train_array_augmented[fromInd:toInd, , , ] <- newImages[[1]]\n    y_augmented <- c(y_augmented, newImages[[2]])\n}\n```\n\n\n## Building a CNN Model\n```{r echo = TRUE}\nmodel <- keras_model_sequential()\n\nmodel %>% layer_conv_2d(kernel_size = c(3,3), filters = 8, strides = 1,\n                        activation = \"relu\", padding = \"same\",\n                        input_shape = c(width, height, numInputChannels),\n                        data_format=\"channels_last\") %>%\n  layer_batch_normalization() %>%\n  layer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n\nmodel %>% layer_conv_2d(kernel_size = c(3,3), filters = 16, strides = 1,\n                        activation = \"relu\", padding = \"same\",\n                        input_shape = c(width, height, numInputChannels),\n                        data_format=\"channels_last\") %>%\n  layer_batch_normalization() %>%\n  layer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n```\n\n\n## Building a CNN Model\n(Continued)\n```{r echo = TRUE}\n\nmodel %>% layer_conv_2d(kernel_size = c(3,3), filters = 32, strides = 1,\n                        activation = \"relu\", padding = \"same\",\n                        input_shape = c(width, height, numInputChannels),\n                        data_format=\"channels_last\") %>%\n  layer_batch_normalization() %>%\n  layer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n```\n\n\n\n## Building a CNN Model\n(Continued)\n```{r echo = TRUE}\nmodel %>% layer_flatten()\nmodel %>% layer_dropout(0)\nmodel %>% layer_dense(units = 64, activation = \"relu\")\nmodel %>% layer_dropout(0)\nmodel %>% layer_dense(units = 64, activation = \"relu\")\nmodel %>% layer_dropout(0)\nmodel %>% layer_dense(units = 64, activation = \"relu\")\nmodel %>% layer_dropout(0)\nmodel %>% layer_dense(units = 1, activation = \"relu\")\n```\n\n\n## Compiling the Model\n- We will use the <span style=\"color:#16a085\">RMSProp</span> optimiser but specify a <span style=\"color:#16a085\">learning rate</span> of 0.001 and use a <span style=\"color:#16a085\">decay</span> in the learning rate of 0.1.\n- Our loss function is mean square error (MSE).\n```{r echo = TRUE}\nmodel %>% compile(\n  loss = 'mse',\n  optimizer = optimizer_rmsprop(lr = 0.001),\n  metrics = c('mae')\n)\n```\n\n\n## Training the Model\n```{r echo = TRUE}\nuseAugmentedData = TRUE\nif(useAugmentedData)\n{\n  history <- model %>% fit(\n    x = train_array_augmented, y = as.numeric(y_augmented),\n    epochs = 20, batch_size = 8, validation_data = list(test_array, as.numeric(testData$y))\n  )\n}\nif(!useAugmentedData)\n{\n  history <- model %>% fit(\n    x = train_array, y = as.numeric(trainData$y),\n    epochs = 20, batch_size = 8, validation_data = list(test_array, as.numeric(testData$y))\n  )\n}\n```\n\n\n## Training the Model\n```{r fig2, fig.height = 4, fig.width = 8, fig.align = \"center\", echo = TRUE}\nplot(history)\n```\n\n## Assessing Predictive Error\n- Let's calculate the standard deviation of the error between prediction and truth for the validation data.\n```{r echo = TRUE}\npredictions <-  predict(model, test_array)\ntruth <- testData$y\nprint(mean(predictions - truth))\nprint(sd(predictions - truth))\n```\n\n\n## Assessing Predictive Error\n- Let's plot the predicted cell counts against the true cell counts and add the line of equivalence in red.\n```{r fig1, fig.height = 4, fig.width = 8, fig.align = \"center\", echo = TRUE}\nplot(truth, predictions, xlab = \"True Cell Count\", \n     ylab = \"Predicted Cell Count\", xlim = c(0, 350), ylim = c(0, 350))\nabline(0,1, col = \"red\")\n```\n\n## Some things to try\n- Does Data augmentation help to improve the prediction?\n- How could you use cross-validation to better assess the predictive performance with and without data augmentation?\n- Does converting the images to grayscale have any impact on predictive performance?\n- How do your results change if you reduce the number of filters in the convolutional layers or the number of units in the dense layers?\n\n\n\n",
    "created" : 1574814264112.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4109731280",
    "id" : "13920310",
    "lastKnownWriteTime" : 1574814427,
    "last_content_update" : 1574814427182,
    "path" : "~/Dropbox/Deep_Learning_Short_Course/CourseSlides/Exercise 4 - Cells Dataset/Cells.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}
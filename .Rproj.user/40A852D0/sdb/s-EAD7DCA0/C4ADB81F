{
    "collab_server" : "",
    "contents" : "---\ntitle: \"The Carcinoma Dataset\"\nauthor: <span style=\"color:#16a085\">Christopher K. Wikle & Dan Pagendam</span>\noutput: ioslides_presentation\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n\n## The Carcinoma Dataset\n- This dataset is taken from Janowczyk, A. and Madabhushi, A. (2016). Deep learning for digital pathology image analysis: A comprehensive tutorial with selected use cases. Journal of Pathology Informatics 7:29.\n- https://www.ncbi.nlm.nih.gov/pubmed/27563488.\n- The full dataset can be downloaded from http://gleason.case.edu/webdata/jpi-dl-tutorial/IDC_regular_ps50_idx5.zip\n\n\n## The Carcinoma Dataset\n- The original dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x\n- From that, 277,524 patches of size 50 x 50 pixels were extracted (198,738 IDC negative and 78,786 IDC positive).\n- In this exercise we use a very small subset of this dataset consisting of 2000 training images and 500 validation images that were randomly sampled from the larger set.\n\n## Required Packages\n- For this exerice you will require the following packages:\n    - <span style=\"color:#16a085\">pbapply</span>\n    - <span style=\"color:#16a085\">EBImage</span>\n- You can install and load these as follows:\n```{r echo = TRUE}\n#install.packages(\"pbapply\")\nlibrary(pbapply)\n\nlibrary(\"devtools\")\n#install_github(\"aoles/EBImage\")\nlibrary(EBImage)\nlibrary(keras)\n```\n\n\n\n## Helper Functions\n- We have included a useful function called <span style=\"color:#16a085\">extract_feature</span>.\n```{r echo = TRUE}\ndropboxLocation <- \"~/Dropbox/Deep_Learning_Short_Course/Examples/Example4_CNN_IDC/\"\nsetwd(dropboxLocation)\nsource(\"functions/extract_feature.R\")\n```\n\n\n## Load the Carcinoma Data \n- The images are already 50x50 pixels, so no resizing here.\n- You can convert the images to grayscale if desired.\n```{r echo = TRUE}\nwidth <- 50\nheight <- 50\ngrayScale <- FALSE\ntrainData <- extract_feature(paste0(dropboxLocation, \"data/train/\"),\n                             width, height, grayScale, TRUE)\ntestData <- extract_feature(paste0(dropboxLocation, \"data/test/\"), \n                            width, height, grayScale, TRUE)\n```\n\n## Data Formatting for a CNN in Keras\n- Remember, all of our data needs to be in a tensor where the first dimension corresponds to the observations/samples.\n```{r echo = TRUE}\nnumInputChannels <- 3\ntrain_array <- t(trainData$X)\ndim(train_array) <- c(width, height, numInputChannels, \n                      nrow(trainData$X))\ntrain_array <- aperm(train_array, c(4,1,2,3))\n  \ntest_array <- t(testData$X)\ndim(test_array) <- c(width, height, numInputChannels, \n                     nrow(testData$X))\ntest_array <- aperm(test_array, c(4,1,2,3))\n```\n\n\n## Building a CNN Model\n- A standard architecture for a CNN are convolutional, batch normalisation, and max-pooling layers repeated in series.\n```{r echo = TRUE}\nmodel <- keras_model_sequential()\n\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n```\n\n\n## Building a CNN Model (Continued)\n- After the deep convolutional parts, the tensors are flattened (i.e. a 2D image to a vector).\n- The flattened features are then put through a FFNN with a single node for binary classification.\n```{r echo = TRUE}\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n\nmodel %>% layer_flatten()\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>%layer_dense(units = 1, activation = \"sigmoid\")\n```\n\n## Compiling the model\n- For binary classification, the standard loss function is binary cross-entropy.\n```{r echo = TRUE}\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = optimizer_rmsprop(lr = 0.0001),\n  metrics = c('accuracy')\n)\n```\n\n\n## Training the Model\n- Let's train the model for 50 epochs and see whether the model overfits.\n```{r echo = TRUE}\nhistory <- model %>% fit(\n  x = train_array, y = as.numeric(trainData$y),\n  epochs = 50, batch_size = 32, validation_data =\n    list(test_array,as.numeric(testData$y))\n)\n```\n\n\n## Training the Model\n- Let's train the model for 50 epochs and see whether the model overfits.\n```{r  fig1, fig.height = 3, fig.width = 8, fig.align = \"center\", echo = TRUE}\nplot(history)\n```\n\n## Training the Model\n- It looks as though the prediction accuracy peaks at around 80% on the validation data.\n- It is clear that the loss for the training and validation data start to diverge by around 20 epochs, indicating overfitting.\n- We'll re-initialise the model and train it again, but this time specify only 20 epochs.\n\n\n\n## Rebuilding the CNN Model\n```{r echo = TRUE}\nmodel <- keras_model_sequential()\n\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n```\n\n\n## Rebuilding the CNN Model (Continued)\n- After the deep convolutional parts, the tensors are flattened (i.e. a 2D image to a vector).\n- The flattened features are then put through a FFNN with a single node for binary classification.\n```{r echo = TRUE}\nmodel %>% layer_conv_2d(kernel_size = c(5,5), filters = 8,\n          strides = 1, activation = \"relu\", padding = \"same\", \n          input_shape = c(width, height, numInputChannels),\n          data_format=\"channels_last\") %>%\nlayer_batch_normalization() %>%\nlayer_max_pooling_2d(pool_size = c(2,2), padding = \"same\")\n\nmodel %>% layer_flatten()\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>% layer_dense(units = 8, activation = \"relu\")\nmodel %>%layer_dense(units = 1, activation = \"sigmoid\")\n```\n\n## Recompiling the model\n- For binary classification, the standard loss function is binary cross-entropy.\n```{r echo = TRUE}\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = optimizer_rmsprop(lr = 0.0001),\n  metrics = c('accuracy')\n)\n```\n\n\n## Retraining the Model\n- Let's train the model for 50 epochs and see whether the model overfits.\n```{r echo = TRUE}\nhistory <- model %>% fit(\n  x = train_array, y = as.numeric(trainData$y),\n  epochs = 20, batch_size = 32, validation_data =\n    list(test_array,as.numeric(testData$y))\n)\n```\n\n## Retraining the Model\n```{r fig2, fig.height = 3, fig.width = 8, fig.align = \"center\", echo = TRUE}\nplot(history)\n```\n\n## Retraining the Model\n```{r echo = TRUE}\n# We can obtain the outputs of the model (sigmoid activation)\nprobabilities <- predict_proba(model, test_array)\n# We obtain the predicted classes for the test/validation dataset\npredictions <-  predict_classes(model, test_array)\ntruth <- testData$y\npropCorrect <- sum(predictions == truth)/length(truth)\nprint(propCorrect)\n```\n\n## Checking Model Performance\n```{r}\nrandom <- sample(1:nrow(testData$X), 16)\nplot_preds <- predictions[random,]\nplot_probs <- as.vector(round(probabilities[random,], 2))\nplot_truth <- truth[random]\n\npar(mfrow = c(4, 4), mar = rep(0, 4))\nfor(i in 1:length(random)){\n  if(grayScale)\n  {\n    image(t(apply(test_array[random[i],,,], 2, rev)),\n          col = gray.colors(12), axes = F)\n  }\n  if(!grayScale)\n  {\n    image(t(apply(test_array[random[i],,,1], 2, rev)),\n          col = gray.colors(12), axes = F)\n  }\n    legend(\"top\", legend = paste0(\"Pred: \", ifelse(plot_preds[i] == 0, \"IDC Neg.\", \"IDC Pos.\")),\n         text.col = ifelse(plot_preds[i] == 0, 4, 2), bty = \"n\", text.font = 2)\n  legend(\"center\", legend = plot_probs[i], bty = \"n\", cex = 2, text.col = \"black\")\n  legend(\"bottom\", legend = paste0(\"Truth: \", ifelse(plot_truth[i] == 0, \"IDC Neg.\", \"IDC Pos.\")), text.col = ifelse(plot_truth[i] == 0, 4, 2), bty = \"n\", text.font = 2)\n}\n\n```\n\n## Some things to try\n- Does converting the images to grayscale have any impact on predictive performance?\n- How do your results change if you reduce the number of filters in the convolutional layers or the number of units in the dense layers?\nDoes the model overfit more dramatically (i.e. the history plot) when the model has more parameters?\n- Where could you incorporate dropout layers into the model?\n\n\n",
    "created" : 1574812568787.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3960346987",
    "id" : "C4ADB81F",
    "lastKnownWriteTime" : 1574812834,
    "last_content_update" : 1574812834693,
    "path" : "~/Dropbox/Deep_Learning_Short_Course/CourseSlides/Exercise 3 - Carcinoma Dataset/Carcinoma.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}
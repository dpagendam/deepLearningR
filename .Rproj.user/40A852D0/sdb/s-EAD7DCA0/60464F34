{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Deep Learning for Environmentric, Biological, and Agricultural Applications\"\noutput:\n  beamer_presentation: default\n  ioslides_presentation: default\n  slidy_presentation: default\n---\n\nSlide copies\n- Workshop material printed in Officeworks Sunday\n\nCar\n- Monday December 9, 2:30pm Qantas QF530 (pickup)\n- Friday, 8.10am Air New Zealand (dropoff)\n\n\nEdit Docker file\nthen do docker build -t dpagendam/kerasr .\n\ndocker image ls\n\ndocker push dpagendam/kerasr\n\n\n\nTry to install Docker Desktop:\n - https://docs.docker.com/docker-for-mac/\n - https://docs.docker.com/docker-for-windows/\n \n\nIf your computer doesn't meet the specs above, then Install Docker Toolbox:\n - https://docs.docker.com/toolbox/toolbox_install_mac/\n - https://docs.docker.com/toolbox/toolbox_install_windows/\n \n\nOpen either a MacOS Terminal or a Windows Command Line Window and type:\n - docker pull dpagendam/kerasr\n \n \ndocker run -p 8787:8787 -e PASSWORD=workshop --name rstudio --rm dpagendam/kerasr\n\n# To get a command line in the container:\n#docker exec -it rstudio /bin/bash\n\nNavigate to: \nlocalhost:8787\nor possibly 127.0.0.1:8787\n\n\ndocker start rstudio\ndocker stop rstudio\n\ndocker container ls\ndocker container ls -a\ndocker container rm <name>\ndocker container kill <name>\n \n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n\n## Today's Exercises\n\n- Exercise 1: The Buzz Dataset (FFNN for classification)\n- Exercise 2: The Wheat Dataset (FFNN for regression)\n- Exercise 3: The IDC Dataset (CNN for classification)\n- Exercise 4: The Cell Count Dataset (CNN for regression)\n- Exercise 5: The Drought Dataset (RNN for regression)\n\n\n## Today's Software\n\n- RStudio (recommended) or an R Terminal Window\n- The Keras and Tensorflow R Packages\n- Python ???\n- Tensorflow for Python ???\n\n## Today's Software\n\n- Installation instructions for Windows, MacOS and Linux are available here:\n- ???\n\n## Exercise 1: The Buzz Dataset\n\n- We will use audio data collected from six species of mosquito and use a simple Feed-forward Neural Network (FFNN) to try and classify them correctly.\n- The audio files have been converted to a periodogram that highlights which frequencies in the recorded audio are most prominent.\n- We will look at how Singular Value Decomposition (SVD) can be used to reduce the dimensionality of the inputs prior to model building.\n\n## Exercise 1: Key Concepts\n\n- The architecture of Feed-forward Neural Networks (FFNNs)\n- Activation functions\n- 'One-hot encoding'\n- Formatting and scaling training and test data\n- Optimisers\n- Epochs and batch size\n- Loss functions and metrics\n\n\n## Exercise 2: The Wheat Dataset\n\n- We will use data collected from an agricultural model named APSIM.\n- The data consists of meteorological data and fertiliser application data (predictors) for each growing season.\n- We also have the yield of the wheat crop (response variable) from the model which we will try to predict based on the predictors.\n- We will see how a neural network with multiple outputs can be used to give a predictive distribution (e.g. Mixture-density networks).\n\n## Exercise 2: Key Concepts\n\n- The architecture of Feed-forward Neural Networks (FFNNs)\n- Activation functions\n- Formatting and scaling training and test data\n- Optimisers\n- Epochs and batch size\n- Custom loss functions in Keras\n\n\n## Exercise 3: The Invasive Ductal Carcinoma (IDC) Dataset\n\n- We will use 50 x 50 pixel images extracted from biopsy slides (image data) of aggressive and non-aggresive IDCs.\n- Simple convolutional neural networks will be used to predict whether or not the image is of an aggressive IDC or not.\n- _Possibly_ we will attempt to ascertain which parts of the images are most influential in the classification of the image (e.g. Deep Taylor methods).\n\n## Exercise 3: Key Concepts\n\n- The architecture of Convolutional Neural Networks (CNNs)\n- Convolution kernels\n- Filters, strides and padding\n- Batch normalisation\n- Max-pooling\n- Binary cross-entropy loss\n- Sigmoid activation function (on the output node)\n\n\n## Exercise 4: The Cell Count Dataset\n\n- We will use 64 x 64 pixel images of cells fluorescing blue on a black background.\n- Simple convolutional neural networks will be used to try and count the number of cells in the image.\n- In this example, we only have a limited number of images (200) to train our neural network.  We will therefore explore the idea of \"data augmentation'' to try and extract more training opportunities from our limited dataset.\n\n## Exercise 4: Key Concepts\n\n- The architecture of Convolutional Neural Networks (CNNs)\n- Convolution kernels\n- Filters, strides and padding\n- Batch normalisation\n- Max-pooling\n- Dropout\n- Data Augmentation\n\n\n## Exercise 5: The Drought Dataset\n\n- The data here consists of monthly sea surface temperature (SST) rasters and time series of rainfall anomaly in the Murray-Darling Basin, Australia.\n- We will attempt to create a 3-month out forecast of the rainfall anomaly using the spatio-temporal SST data.\n- We will create a type of Recurrent Neural Network called a Long Short-term Memory model (or LSTM) to provide a predictive distribution for the forecast.\n\n## Exercise 5: Key Concepts\n\n- The architecture of Recurrent Neural Networks (RNNs), particularly LSTMs\n- Singular Value Decomposition for dimension reduction\n- Embedding vectors\n- Custom loss functions in Keras\n- Callbacks in Keras (i.e. early stopping)\n- Checking coverage of predictive distributions\n\n\n\n\n",
    "created" : 1574802468568.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1469956331",
    "id" : "60464F34",
    "lastKnownWriteTime" : 1574802539,
    "last_content_update" : 1574802539396,
    "path" : "~/Desktop/Exercise Summary.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}